{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899f7db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01f45fe",
   "metadata": {},
   "source": [
    "## Results from the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92753672",
   "metadata": {},
   "outputs": [],
   "source": [
    "GRU = {\n",
    "    'mort_hosp':{'auc': 0.8504, 'auprc': 0.5215, 'F1': 0.4229},\n",
    "    'mort_icu': {'auc': 0.8632, 'auprc': 0.4651, 'F1': 0.3630},\n",
    "    'los_3':    {'auc': 0.6740, 'auprc': 0.6017, 'F1': 0.5336},\n",
    "    'los_7':    {'auc': 0.7054, 'auprc': 0.1625, 'F1': 0.0233},\n",
    "}\n",
    "\n",
    "# Averaged Multimodal\n",
    "\n",
    "word2vec_avg = {\n",
    "    'mort_hosp':{'auc': 0.8642, 'auprc': 0.5422, 'F1': 0.4542},\n",
    "    'mort_icu': {'auc': 0.8717, 'auprc': 0.4847, 'F1': 0.4230},\n",
    "    'los_3':    {'auc': 0.6863, 'auprc': 0.6181, 'F1': 0.5419},\n",
    "    'los_7':    {'auc': 0.7159, 'auprc': 0.1791, 'F1': 0.0135},\n",
    "}\n",
    "\n",
    "fastText_avg = {\n",
    "    'mort_hosp':{'auc': 0.8609, 'auprc': 0.5447, 'F1': 0.4550},\n",
    "    'mort_icu': {'auc': 0.8714, 'auprc': 0.4836, 'F1': 0.4291},\n",
    "    'los_3':    {'auc': 0.6855, 'auprc': 0.6159, 'F1': 0.5446},\n",
    "    'los_7':    {'auc': 0.7131, 'auprc': 0.1757, 'F1': 0.0102},\n",
    "}\n",
    "\n",
    "concat_avg = {\n",
    "    'mort_hosp':{'auc': 0.8598, 'auprc': 0.5419, 'F1': 0.4566},\n",
    "    'mort_icu': {'auc': 0.8690, 'auprc': 0.4828, 'F1': 0.4076},\n",
    "    'los_3':    {'auc': 0.6861, 'auprc': 0.6169, 'F1': 0.5470},\n",
    "    'los_7':    {'auc': 0.7159, 'auprc': 0.1767, 'F1': 0.0137},\n",
    "}\n",
    "\n",
    "\n",
    "# Proposed Model\n",
    "\n",
    "word2vec_proposed = {\n",
    "    'mort_hosp':{'auc': 0.8755, 'auprc': 0.5587, 'F1': 0.4723},\n",
    "    'mort_icu': {'auc': 0.8835, 'auprc': 0.4923, 'F1': 0.4302},\n",
    "    'los_3':    {'auc': 0.6954, 'auprc': 0.6268, 'F1': 0.5504},\n",
    "    'los_7':    {'auc': 0.7255, 'auprc': 0.1878, 'F1': 0.0158},\n",
    "}\n",
    "\n",
    "fastText_proposed = {\n",
    "    'mort_hosp':{'auc': 0.8715, 'auprc': 0.5568, 'F1': 0.4687},\n",
    "    'mort_icu': {'auc': 0.8785, 'auprc': 0.4878, 'F1': 0.4309},\n",
    "    'los_3':    {'auc': 0.6961, 'auprc': 0.6255, 'F1': 0.5587},\n",
    "    'los_7':    {'auc': 0.7181, 'auprc': 0.1801, 'F1': 0.0108},\n",
    "}\n",
    "\n",
    "concat_proposed = {\n",
    "    'mort_hosp':{'auc': 0.8698, 'auprc': 0.5535, 'F1': 0.4638},\n",
    "    'mort_icu': {'auc': 0.8766, 'auprc': 0.4874, 'F1': 0.4224},\n",
    "    'los_3':    {'auc': 0.6993, 'auprc': 0.6277, 'F1': 0.5582},\n",
    "    'los_7':    {'auc': 0.7192, 'auprc': 0.1825, 'F1': 0.0138},\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10bceace",
   "metadata": {},
   "source": [
    "Place them into pandas df to be used later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2246d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# paper_results_07\n",
    "paper_results_07 = pd.DataFrame.from_dict(GRU, orient='index')\n",
    "paper_results_07 = paper_results_07.reset_index()\n",
    "paper_results_07.rename(columns={'index':'task'}, inplace=True)\n",
    "paper_results_07['layer'] = 'GRU'\n",
    "\n",
    "# paper_results_08\n",
    "word2vec_avg_pd = pd.DataFrame.from_dict(word2vec_avg, orient='index')\n",
    "word2vec_avg_pd = word2vec_avg_pd.reset_index()\n",
    "word2vec_avg_pd.rename(columns={'index':'task'}, inplace=True)\n",
    "word2vec_avg_pd['embedding'] = 'word2vec'\n",
    "\n",
    "fastText_avg_pd = pd.DataFrame.from_dict(fastText_avg, orient='index')\n",
    "fastText_avg_pd = fastText_avg_pd.reset_index()\n",
    "fastText_avg_pd.rename(columns={'index':'task'}, inplace=True)\n",
    "fastText_avg_pd['embedding'] = 'fasttext'\n",
    "\n",
    "concat_avg = pd.DataFrame.from_dict(word2vec_avg, orient='index')\n",
    "concat_avg = concat_avg.reset_index()\n",
    "concat_avg.rename(columns={'index':'task'}, inplace=True)\n",
    "concat_avg['embedding'] = 'concat'\n",
    "\n",
    "paper_results_08 = pd.concat([word2vec_avg_pd, fastText_avg_pd, concat_avg])\n",
    "\n",
    "# paper_results_09\n",
    "word2vec_proposed_pd = pd.DataFrame.from_dict(word2vec_proposed, orient='index')\n",
    "word2vec_proposed_pd = word2vec_proposed_pd.reset_index()\n",
    "word2vec_proposed_pd.rename(columns={'index':'task'}, inplace=True)\n",
    "word2vec_proposed_pd['embedding'] = 'word2vec'\n",
    "\n",
    "fastText_proposed_pd = pd.DataFrame.from_dict(fastText_proposed, orient='index')\n",
    "fastText_proposed_pd = fastText_proposed_pd.reset_index()\n",
    "fastText_proposed_pd.rename(columns={'index':'task'}, inplace=True)\n",
    "fastText_proposed_pd['embedding'] = 'fasttext'\n",
    "\n",
    "concat_proposed_pd = pd.DataFrame.from_dict(concat_proposed, orient='index')\n",
    "concat_proposed_pd = concat_proposed_pd.reset_index()\n",
    "concat_proposed_pd.rename(columns={'index':'task'}, inplace=True)\n",
    "concat_proposed_pd['embedding'] = 'concat'\n",
    "\n",
    "paper_results_09 = pd.concat([word2vec_avg_pd, fastText_avg_pd, concat_avg])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3df582d",
   "metadata": {},
   "source": [
    "## Functions to produce tabular outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c9a29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add n blank rows\n",
    "def add_blank_rows_df(df, after_each_n):\n",
    "    new_index = pd.RangeIndex(len(df) + np.ceil(len(df)/after_each_n))\n",
    "    new_df = pd.DataFrame('', index=new_index, columns=df.columns)\n",
    "    \n",
    "    ids = []\n",
    "    jump = 0\n",
    "    for i in range(0, len(df)):\n",
    "        ids.append(i + np.floor(i/after_each_n))\n",
    "        \n",
    "    new_df.loc[ids] = df.values\n",
    "    return new_df\n",
    "\n",
    "def get_results(result_path: str,\n",
    "                paper_results,\n",
    "                model_category: str,\n",
    "                sort_by:str,\n",
    "                group_by: list,\n",
    "                exp_naming: list,\n",
    "                var_type: str):\n",
    "    \n",
    "    result_dists = []\n",
    "    exps = os.listdir(result_path)\n",
    "    \n",
    "    # Pulls the results from the `.p` files \n",
    "    for exp in exps:\n",
    "        if '.p' not in exp:\n",
    "            continue\n",
    "        result_dict = pd.read_pickle(os.path.join(result_path, exp))\n",
    "        result_dict[exp_naming[0]], result_dict[exp_naming[1]], result_dict[exp_naming[2]], result_dict[exp_naming[3]] = exp.split(\"-\")[:4]\n",
    "        result_dict[\"model_category\"] = model_category\n",
    "        result_dists.append(result_dict)\n",
    "        \n",
    "    result = pd.DataFrame(result_dists)\n",
    "    result.sort_values(by=['task', sort_by], inplace=True, ascending=False)\n",
    "\n",
    "    # Generate the summary results table\n",
    "    summary_results = get_summary_results(result, \n",
    "                                          model_category,\n",
    "                                          sort_by,\n",
    "                                          group_by,\n",
    "                                          exp_naming,\n",
    "                                          var_type)\n",
    "    \n",
    "    \n",
    "    results_difference = get_results_difference(result,\n",
    "                                                paper_results,\n",
    "                                                model_category,\n",
    "                                                sort_by,\n",
    "                                                group_by,\n",
    "                                                exp_naming,\n",
    "                                                var_type)\n",
    "    \n",
    "    return result, summary_results, results_difference\n",
    "\n",
    "def get_summary_results(result, \n",
    "                        model_category: str,\n",
    "                        sort_by:str,\n",
    "                        group_by: list,\n",
    "                        exp_naming: list,\n",
    "                        var_type: str):\n",
    "    \n",
    "    summary_results = result.groupby(by=group_by).agg({\"auc\":['mean','std'], \"auprc\":['mean','std'], \"F1\":['mean','std'], 'acc':['mean','std']})\n",
    "    summary_results.columns = summary_results.columns.map('_'.join).str.strip('_')\n",
    "    summary_results.reset_index(inplace=True)\n",
    "    summary_results[\"model_category\"] = model_category\n",
    "    \n",
    "    # Get values in terms of %\n",
    "    for col in ['auc_mean', 'auc_std', 'auprc_mean', 'auprc_std',\n",
    "       'F1_mean', 'F1_std', 'acc_mean', 'acc_std']:\n",
    "       summary_results[col] = summary_results[col] * 100\n",
    "    \n",
    "    # Rename the tasks\n",
    "    task_mapping = {\n",
    "        \"los_3\": \"LOS > 3 Days\",\n",
    "        \"los_7\": \"LOS > 7 Days\",\n",
    "        \"mort_hosp\": \"In-Hospital Mortality\",\n",
    "        \"mort_icu\": \"In-ICU Mortality\"\n",
    "    }\n",
    "    for k, v in task_mapping.items():\n",
    "        summary_results.loc[summary_results[\"task\"] == k, \"task\"] = v\n",
    "    \n",
    "    # Format the numeric results\n",
    "    for matric in [\"auc\", \"auprc\", \"F1\", \"acc\"]:\n",
    "        summary_results[matric] = summary_results[[f\"{matric}_mean\", f\"{matric}_std\"]].apply(lambda x: \"{:.2f} +/- {:.3f}\".format(x[0], x[1]), axis=1)\n",
    "    \n",
    "    # Order the results in the manner desired\n",
    "    summary_results = summary_results[[\"task\", \"model_category\",var_type, \"auc\", \"auprc\", \"F1\"]]\n",
    "\n",
    "    summary_results.sort_values(by=[sort_by], inplace=True, ascending=False)\n",
    "    summary_results.sort_values(by=['task'], inplace=True, ascending=True)\n",
    "\n",
    "    return summary_results\n",
    "\n",
    "\n",
    "def get_results_difference(result, \n",
    "                           paper_results,\n",
    "                           model_category: str,\n",
    "                           sort_by:str,\n",
    "                           group_by: list,\n",
    "                           exp_naming: list,\n",
    "                           var_type: str):\n",
    "    \n",
    "    results_difference = result.groupby(by=group_by).agg({\"auc\":['mean'], \"auprc\":['mean'], \"F1\":['mean']})\n",
    "    results_difference = results_difference.rename(columns={'mean':''})\n",
    "    results_difference.columns = results_difference.columns.map('_'.join).str.strip('_')\n",
    "    results_difference.reset_index(inplace=True)\n",
    "    results_difference[\"model_category\"] = model_category\n",
    "    \n",
    "    # Take the difference between the reported results in the paper and what we have recorded [auc, auprc, F1]\n",
    "    results_difference = results_difference.assign(auc = results_difference['auc'] - results_difference.merge(paper_results, \n",
    "                                                                                         on=['task',var_type], \n",
    "                                                                                         suffixes=('','_y'), \n",
    "                                                                                         how='left')['auc_y'])  \n",
    "    results_difference = results_difference.assign(auprc = results_difference['auprc'] - results_difference.merge(paper_results, \n",
    "                                                                                         on=['task',var_type], \n",
    "                                                                                         suffixes=('','_y'), \n",
    "                                                                                         how='left')['auprc_y']) \n",
    "    results_difference = results_difference.assign(F1 = results_difference['F1'] - results_difference.merge(paper_results, \n",
    "                                                                                         on=['task',var_type], \n",
    "                                                                                         suffixes=('','_y'), \n",
    "                                                                                         how='left')['F1_y']) \n",
    "    # If no data from paper, then set to '-'\n",
    "    results_difference.loc[results_difference.merge(paper_results, \n",
    "                                                     on=['task',var_type], \n",
    "                                                     suffixes=('','_y'), \n",
    "                                                     how='left')['auc_y'].isnull(), 'auc'] = '-'\n",
    "    results_difference.loc[results_difference.merge(paper_results, \n",
    "                                                     on=['task',var_type], \n",
    "                                                     suffixes=('','_y'), \n",
    "                                                     how='left')['auprc_y'].isnull(), 'auprc'] = '-'\n",
    "    results_difference.loc[results_difference.merge(paper_results, \n",
    "                                                     on=['task',var_type], \n",
    "                                                     suffixes=('','_y'), \n",
    "                                                     how='left')['F1_y'].isnull(), 'F1'] = '-'\n",
    "\n",
    "\n",
    "    # Get values in terms of %\n",
    "    for col in ['auc', 'auprc', 'F1']:\n",
    "       results_difference[col] = results_difference[col] * 100\n",
    "    \n",
    "    # Rename the tasks\n",
    "    task_mapping = {\n",
    "        \"los_3\": \"LOS > 3 Days\",\n",
    "        \"los_7\": \"LOS > 7 Days\",\n",
    "        \"mort_hosp\": \"In-Hospital Mortality\",\n",
    "        \"mort_icu\": \"In-ICU Mortality\"\n",
    "    }\n",
    "    for k, v in task_mapping.items():\n",
    "        results_difference.loc[results_difference[\"task\"] == k, \"task\"] = v\n",
    "    \n",
    "    # Format the numeric results\n",
    "    for metric in [\"auc\", \"auprc\", \"F1\"]:\n",
    "        results_difference[metric] = results_difference[[metric]].apply(lambda x: \"{:.2f}\".format(x[0]) if not isinstance(x[0], str) else '-', axis=1)\n",
    "    \n",
    "    # Order the results in the manner desired\n",
    "    results_difference = results_difference[[\"task\", \"model_category\",var_type, \"auc\", \"auprc\", \"F1\"]]\n",
    "    \n",
    "    results_difference.sort_values(by=[sort_by], inplace=True, ascending=False)\n",
    "    results_difference.sort_values(by=['task'], inplace=True, ascending=True)\n",
    "    \n",
    "    return results_difference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6409e384",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "09605c97",
   "metadata": {},
   "source": [
    "# Only time-series data results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733df62c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "results_07, summary_results_07, results_difference_07 = get_results(\n",
    "    result_path=\"results/07-baseline/GRU/hidden_units_256\",\n",
    "    paper_results=paper_results_07,\n",
    "    model_category=\"GRU\",\n",
    "    sort_by=\"auc\",\n",
    "    group_by=[\"task\", \"layer\"],\n",
    "    exp_naming=[\"hidden_units\",\"layer\",\"task\",\"iteration\"],\n",
    "    var_type=\"layer\")\n",
    "\n",
    "summary_results_07"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f482fc9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_difference_07"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb315129",
   "metadata": {},
   "source": [
    "# Baseline time-series and NLP data results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e799485",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "results_08, summary_results_08, results_difference_08 = get_results(\n",
    "    result_path=\"results/08-multimodal\",\n",
    "    paper_results=paper_results_08,\n",
    "    model_category=\"Average Multimodal\",\n",
    "    sort_by=\"auc\",\n",
    "    group_by=[\"task\", \"embedding\"],\n",
    "    exp_naming=[\"layer\",\"hidden_units\",\"embedding\",\"task\"],\n",
    "    var_type=\"embedding\")\n",
    "\n",
    "summary_results_08_print = add_blank_rows_df(summary_results_08, 5)\n",
    "summary_results_08_print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2ae926",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_difference_08_print = add_blank_rows_df(results_difference_08, 5)\n",
    "results_difference_08_print"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801273d4",
   "metadata": {},
   "source": [
    "# Proposed models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da6afed",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_09, summary_results_09, results_difference_09 = get_results(\n",
    "    result_path=\"results/09-cnn\",\n",
    "    paper_results=paper_results_09,\n",
    "    model_category=\"Proposed Model\",\n",
    "    sort_by=\"embedding\",\n",
    "    group_by=[\"task\", \"embedding\"],\n",
    "    exp_naming=[\"sequence_name\",\"hidden_unit_size\",\"embedding\",\"task\"],\n",
    "    var_type=\"embedding\")\n",
    "\n",
    "summary_results_09_print = add_blank_rows_df(summary_results_09, 5)\n",
    "summary_results_09_print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6020b8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_difference_09_print = add_blank_rows_df(results_difference_09, 5)\n",
    "results_difference_09_print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49183feb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cf726f1f",
   "metadata": {},
   "source": [
    "# Make same as paper (Table 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c2b611",
   "metadata": {},
   "outputs": [],
   "source": [
    "def table_3(df1, df2):\n",
    "\n",
    "    table_3_df = pd.concat([df1, df2])\n",
    "    table_3_df = table_3_df.drop(columns=['layer']).fillna('')\n",
    "    table_3_df = table_3_df[[\"task\", \"model_category\",'embedding', \"auc\", \"auprc\", \"F1\"]]\n",
    "    table_3_df.sort_values(by=['task', 'embedding'], inplace=True, ascending=True)\n",
    "    table_3_df = add_blank_rows_df(table_3_df, 6)\n",
    "    return table_3_df\n",
    "\n",
    "summary_results_paper_1 = table_3(summary_results_07, summary_results_08)\n",
    "summary_results_paper_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701c6e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_difference_paper_1 = table_3(results_difference_07, results_difference_08)\n",
    "results_difference_paper_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4911f431",
   "metadata": {},
   "source": [
    "## Table 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4704dd",
   "metadata": {},
   "source": [
    "### Determine best model from table 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbeef4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = [\"los_3\",\"los_7\",\"mort_hosp\", \"mort_icu\" ]\n",
    "\n",
    "best_baseline = pd.concat([results_07, results_08]).fillna('-')\n",
    "\n",
    "best_baseline = best_baseline.groupby(by=['task', 'embedding']).agg({\"auc\":['mean', 'std'], \n",
    "                                                                     \"auprc\":['mean', 'std'],\n",
    "                                                                     \"F1\":['mean', 'std']})\n",
    "best_baseline.columns = best_baseline.columns.map('_'.join).str.strip('_')\n",
    "best_baseline.reset_index(inplace=True)\n",
    "\n",
    "best_baseline_auc = best_baseline.loc[best_baseline.groupby(\"task\")[\"auc_mean\"].idxmax()]\n",
    "best_baseline_auc = best_baseline_auc[[\"task\", \"auc_mean\", 'auc_std']]\n",
    "\n",
    "best_baseline_auprc = best_baseline.loc[best_baseline.groupby(\"task\")[\"auprc_mean\"].idxmax()]\n",
    "best_baseline_auprc = best_baseline_auprc[[\"task\", \"auprc_mean\", 'auprc_std']]\n",
    "\n",
    "best_baseline_F1 = best_baseline.loc[best_baseline.groupby(\"task\")[\"F1_mean\"].idxmax()]\n",
    "best_baseline_F1 = best_baseline_F1[[\"task\", \"F1_mean\", 'F1_std']]\n",
    "\n",
    "best_baseline = best_baseline_auc.merge(best_baseline_auprc, on='task').merge(best_baseline_F1, on='task')\n",
    "\n",
    "\n",
    "# Get values in terms of %\n",
    "for col in ['auc_mean', 'auc_std', 'auprc_mean', 'auprc_std', 'F1_mean', 'F1_std']:\n",
    "   best_baseline[col] = best_baseline[col] * 100\n",
    "\n",
    "# Rename the tasks\n",
    "task_mapping = {\n",
    "    \"los_3\": \"LOS > 3 Days\",\n",
    "    \"los_7\": \"LOS > 7 Days\",\n",
    "    \"mort_hosp\": \"In-Hospital Mortality\",\n",
    "    \"mort_icu\": \"In-ICU Mortality\"\n",
    "}\n",
    "for k, v in task_mapping.items():\n",
    "    best_baseline.loc[best_baseline[\"task\"] == k, \"task\"] = v\n",
    "\n",
    "# Format the numeric results\n",
    "for metric in [\"auc\", \"auprc\", \"F1\"]:\n",
    "    best_baseline[metric] = best_baseline[[f\"{metric}_mean\", f\"{metric}_std\"]].apply(lambda x: \"{:.2f} +/- {:.3f}\".format(x[0], x[1]), axis=1)\n",
    "\n",
    "best_baseline[\"model_category\"] = 'Best Baseline'\n",
    "best_baseline[\"embedding\"] = '-'\n",
    "\n",
    "# Order the results in the manner desired\n",
    "best_baseline = best_baseline[[\"task\", \"model_category\", 'embedding', \"auc\", \"auprc\", \"F1\"]]\n",
    "\n",
    "best_baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733a4f95",
   "metadata": {},
   "source": [
    "### Add best baseline to CNN results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d069185d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def table_4(df1, df2):\n",
    "\n",
    "    table_3_df = pd.concat([df1, df2])\n",
    "#     table_3_df = table_3_df.drop(columns=['layer']).fillna('')\n",
    "    table_3_df = table_3_df[[\"task\", \"model_category\",'embedding', \"auc\", \"auprc\", \"F1\"]]\n",
    "    table_3_df.sort_values(by=['task', 'model_category', 'embedding'], inplace=True, ascending=True)\n",
    "    table_3_df = add_blank_rows_df(table_3_df, 6)\n",
    "    return table_3_df\n",
    "\n",
    "summary_results_paper_2 = table_4(best_baseline, summary_results_09)\n",
    "summary_results_paper_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e36e659",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_difference_paper_2 = table_4(results_difference_07, results_difference_08)\n",
    "# results_difference_paper_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9886382c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(summary_results_paper_1.style.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae396342",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(summary_results_paper_2.style.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a8ae91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,auto:percent"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
